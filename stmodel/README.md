# üß† Module Machine Learning - AquaWatch

## Pr√©diction de la Qualit√© de l'Eau par Deep Learning

**Document technique pour le d√©partement ML**

---

## üìå Contexte du Projet

Ce module utilise un r√©seau de neurones profond pour **pr√©dire la qualit√© de l'eau 24h √† l'avance** dans 10 zones g√©ographiques. Le mod√®le apprend les patterns spatio-temporels des donn√©es capteurs pour anticiper les d√©passements des seuils OMS.

---

## 1Ô∏è‚É£ Les Donn√©es

### 1.1 Source des Donn√©es

Les donn√©es proviennent de **16 capteurs IoT** simul√©s qui mesurent en continu :

| Param√®tre | Unit√© | Plage normale (OMS) | Plage critique |
|-----------|-------|---------------------|----------------|
| **pH** | - | 6.5 - 8.5 | < 6.0 ou > 9.0 |
| **Turbidit√©** | NTU | < 1.0 | > 5.0 |
| **Temp√©rature** | ¬∞C | < 25 | > 30 |

### 1.2 Structure de la Base de Donn√©es (TimescaleDB)

```sql
-- Table des mesures capteurs
CREATE TABLE donnees_capteurs (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMPTZ NOT NULL,      -- Horodatage
    capteur_id VARCHAR(50),              -- Ex: CAPT-1, CAPT-2...
    zone VARCHAR(50),                    -- Ex: Rabat-Centre, Sal√©-Nord...
    ph DECIMAL(5,2),                     -- Valeur pH
    turbidite DECIMAL(5,2),              -- Turbidit√© en NTU
    temperature DECIMAL(5,2),            -- Temp√©rature en ¬∞C
    latitude DECIMAL(10,6),
    longitude DECIMAL(10,6)
);

-- Table des pr√©dictions (sortie du mod√®le)
CREATE TABLE predictions_qualite (
    id BIGSERIAL,
    timestamp TIMESTAMPTZ NOT NULL,       -- Heure de la pr√©diction
    zone_id VARCHAR(50),                  -- Zone pr√©dite
    ph_pred DECIMAL(5,2),                 -- pH pr√©dit
    turbidite_pred DECIMAL(5,2),          -- Turbidit√© pr√©dite
    temperature_pred DECIMAL(5,2),        -- Temp√©rature pr√©dite
    qualite_score DECIMAL(5,2),           -- Score 0-100
    risque_score DECIMAL(5,2),            -- Risque 0-100
    confidence DECIMAL(5,2),              -- Confiance 0-100
    PRIMARY KEY (timestamp, id)
);
```

### 1.3 G√©n√©ration des Donn√©es d'Entra√Ænement

Pour l'entra√Ænement initial, un script g√©n√®re des donn√©es historiques r√©alistes :

```python
# Distribution des donn√©es par zone:
# Zones normales (CAPT-1 √† CAPT-15):
#   - 80% donn√©es bonnes (pH 6.8-7.8, turb < 1.2 NTU)
#   - 15% donn√©es warning 
#   - 5% donn√©es critiques

# Zone Marrakech (CAPT-16) - cas de test critique:
#   - 60% donn√©es critiques (pour tester les alertes)
#   - 30% donn√©es bonnes
#   - 10% donn√©es warning
```

**Variations temporelles appliqu√©es** (cycle jour/nuit) :
```python
hour_factor = sin((heure - 6) √ó œÄ / 12)  # Pic √† 12h, creux √† minuit
temp√©rature = base_temp + hour_factor √ó 3  # ¬±3¬∞C selon l'heure
```

---

## 2Ô∏è‚É£ Architecture du Mod√®le

### 2.1 Choix de l'Architecture : ConvLSTM

**Pourquoi ConvLSTM ?**
- Combine les **convolutions 2D** (pour les corr√©lations spatiales entre zones)
- Avec les **cellules LSTM** (pour les d√©pendances temporelles)
- Parfait pour des donn√©es spatio-temporelles comme les capteurs g√©olocalis√©s

### 2.2 Sch√©ma de l'Architecture

```
                    ENTR√âE
                      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                           ‚îÇ
        ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   S√©quence    ‚îÇ           ‚îÇ     Heure     ‚îÇ
‚îÇ  temporelle   ‚îÇ           ‚îÇ    cible      ‚îÇ
‚îÇ (12, 3, 4, 4) ‚îÇ           ‚îÇ    (0-23)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                           ‚îÇ
        ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ConvLSTM    ‚îÇ           ‚îÇ     Hour      ‚îÇ
‚îÇ   Encoder     ‚îÇ           ‚îÇ   Embedding   ‚îÇ
‚îÇ  (32 hidden)  ‚îÇ           ‚îÇ   (1 ‚Üí 32)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                           ‚îÇ
        ‚îÇ   512 features            ‚îÇ  32 features
        ‚îÇ                           ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº  544 features
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ    Decoder    ‚îÇ
            ‚îÇ     MLP       ‚îÇ
            ‚îÇ 544‚Üí256‚Üí128‚Üí30‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
               SORTIE
            (10 zones √ó 3 params)
```

### 2.3 D√©tail des Composants

#### A) Cellule ConvLSTM

```python
class ConvLSTMCell(nn.Module):
    """
    Cellule LSTM avec convolutions 2D au lieu de multiplications matricielles.
    Permet de capturer les corr√©lations spatiales entre zones voisines.
    """
    def __init__(self, input_dim=3, hidden_dim=32, kernel_size=3):
        # Convolution sur les 4 gates LSTM (input, forget, output, cell)
        self.conv = nn.Conv2d(
            in_channels=input_dim + hidden_dim,  # Concat input + hidden
            out_channels=4 * hidden_dim,          # 4 gates
            kernel_size=3,
            padding=1  # Pr√©serve la taille spatiale
        )
    
    def forward(self, x, state):
        h, c = state  # hidden state, cell state
        
        # Concat√©ner input et hidden state
        combined = concat([x, h], dim=1)
        
        # Convolution puis split en 4 gates
        gates = self.conv(combined)
        i, f, o, g = split(gates, 4)  # input, forget, output, cell gate
        
        # √âquations LSTM classiques
        c_next = sigmoid(f) * c + sigmoid(i) * tanh(g)
        h_next = sigmoid(o) * tanh(c_next)
        
        return h_next, c_next
```

#### B) Hour Embedding

```python
# Pourquoi encoder l'heure ?
# La qualit√© de l'eau varie selon l'heure :
# - Temp√©rature plus √©lev√©e √† midi
# - Turbidit√© plus haute aux heures d'activit√© humaine

class HourEmbedding(nn.Module):
    def __init__(self):
        self.layers = nn.Sequential(
            nn.Linear(1, 16),   # 1 entr√©e (heure normalis√©e)
            nn.ReLU(),
            nn.Linear(16, 32)   # 32 features en sortie
        )
    
    def forward(self, hour):
        # hour est normalis√© : 0h ‚Üí 0.0, 23h ‚Üí 1.0
        return self.layers(hour)
```

#### C) Decoder MLP

```python
self.decoder = nn.Sequential(
    nn.Linear(512 + 32, 256),  # 544 entr√©es (spatial + heure)
    nn.ReLU(),
    nn.Dropout(0.2),           # R√©gularisation
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.Linear(128, 30),        # 10 zones √ó 3 param√®tres
    nn.Sigmoid()               # Sortie normalis√©e [0, 1]
)
```

---

## 3Ô∏è‚É£ Pr√©paration des Donn√©es pour l'Entra√Ænement

### 3.1 Format d'Entr√©e du Mod√®le

```python
# Tenseur d'entr√©e : (batch, sequence, channels, height, width)
# Exemple : (32, 12, 3, 4, 4)
#
# batch = 32          ‚Üí 32 √©chantillons par batch
# sequence = 12       ‚Üí 12 pas de temps historiques
# channels = 3        ‚Üí pH, turbidit√©, temp√©rature
# height √ó width = 4√ó4 ‚Üí Grille spatiale pour 10 zones
```

### 3.2 Mapping Zones ‚Üí Grille 4√ó4

```python
# Les 10 zones sont plac√©es sur une grille 4√ó4 :
ZONES = ['Rabat-Centre', 'Sal√©-Nord', 'Sal√©-Sud', 'Hay-Riad', 
         'Agdal', 'C√¥te-Oc√©an', 'Bouregreg', 'Temara', 
         'Skhirat', 'Marrakech']

# Position dans la grille (row, col) :
def zone_to_grid(zone_idx):
    row = zone_idx % 4   # 0, 1, 2, 3, 0, 1, 2, 3, 0, 1
    col = zone_idx // 4  # 0, 0, 0, 0, 1, 1, 1, 1, 2, 2
    return row, col
```

### 3.3 Normalisation des Donn√©es

```python
# Normalisation Min-Max vers [0, 1] :

# pH : plage r√©aliste [5.5, 9.5] ‚Üí 4 unit√©s
ph_normalized = (ph - 5.5) / 4.0

# Turbidit√© : plage [0, 8] NTU
turb_normalized = turbidite / 8.0

# Temp√©rature : plage [10, 35]¬∞C ‚Üí 25 unit√©s  
temp_normalized = (temperature - 10) / 25.0
```

### 3.4 Cr√©ation des S√©quences d'Entra√Ænement

```python
def create_training_sequences(data):
    """
    Cr√©e des paires (X, y) pour l'entra√Ænement supervis√©.
    X = 12 derniers pas de temps
    y = valeur √† pr√©dire (pas de temps suivant)
    """
    X_list, y_list, hour_list = [], [], []
    
    for zone in ZONES:
        zone_data = data[zone]  # Donn√©es tri√©es par timestamp
        
        for i in range(len(zone_data) - SEQUENCE_LENGTH):
            # X : s√©quence de 12 observations pass√©es
            sequence = zone_data[i : i + SEQUENCE_LENGTH]
            
            # y : observation cible (la suivante)
            target = zone_data[i + SEQUENCE_LENGTH]
            target_hour = target['hour'] / 23.0  # Normaliser heure
            
            X_list.append(sequence)
            y_list.append(target)
            hour_list.append(target_hour)
    
    return np.array(X_list), np.array(y_list), np.array(hour_list)
```

---

## 4Ô∏è‚É£ Entra√Ænement du Mod√®le

### 4.1 Hyperparam√®tres

| Param√®tre | Valeur | Justification |
|-----------|--------|---------------|
| **√âpoques** | 30 | Suffisant pour convergence |
| **Batch size** | 32 | Bon compromis m√©moire/g√©n√©ralisation |
| **Learning rate** | 0.001 | Standard pour Adam |
| **Optimizer** | Adam | Adaptatif, converge vite |
| **Loss** | MSE | R√©gression continue |
| **Train/Val split** | 80/20 | Standard ML |
| **Dropout** | 0.2 | √âvite le surapprentissage |

### 4.2 Boucle d'Entra√Ænement

```python
def train_model(model, X_train, y_train, hours_train, epochs=30):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        
        for batch_x, batch_y, batch_h in DataLoader(dataset, batch_size=32):
            # 1. Forward pass
            predictions = model(batch_x, batch_h)
            
            # 2. Calcul de la loss
            loss = criterion(predictions, batch_y)
            
            # 3. Backward pass
            optimizer.zero_grad()
            loss.backward()
            
            # 4. Mise √† jour des poids
            optimizer.step()
            
            total_loss += loss.item()
        
        # Validation √† chaque √©poque
        val_loss = evaluate(model, X_val, y_val, hours_val)
        
        # Sauvegarder le meilleur mod√®le
        if val_loss < best_loss:
            torch.save(model.state_dict(), 'weights/trained_weights.pth')
```

### 4.3 M√©triques d'√âvaluation

```python
def compute_metrics(y_true, y_pred):
    # MSE : Erreur quadratique moyenne
    mse = mean((y_true - y_pred)¬≤)
    
    # MAE : Erreur absolue moyenne
    mae = mean(|y_true - y_pred|)
    
    # R¬≤ : Coefficient de d√©termination
    r2 = 1 - (sum((y_true - y_pred)¬≤) / sum((y_true - mean(y_true))¬≤))
    
    # Accuracy √† 5% : % pr√©dictions avec erreur < 5%
    acc_5 = mean(|y_true - y_pred| < 0.05) √ó 100
    
    # Accuracy √† 10%
    acc_10 = mean(|y_true - y_pred| < 0.10) √ó 100
    
    return mse, mae, r2, acc_5, acc_10
```

---

## 5Ô∏è‚É£ Phase de Pr√©diction

### 5.1 Pipeline de Pr√©diction

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. R√âCUP√âRATION DES DONN√âES (get_sensor_data_robust)       ‚îÇ
‚îÇ     ‚Üí Cherche donn√©es des 6h, sinon 24h, sinon 7j, 30j      ‚îÇ
‚îÇ     ‚Üí Impute valeurs manquantes avec moyennes OMS           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. CONSTRUCTION DU TENSEUR (build_input_tensor)            ‚îÇ
‚îÇ     ‚Üí Normalise les valeurs                                 ‚îÇ
‚îÇ     ‚Üí Place sur grille 4√ó4                                  ‚îÇ
‚îÇ     ‚Üí R√©p√®te pour 12 pas de temps avec bruit               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. PR√âDICTION POUR CHAQUE HEURE (0h √† 23h)                 ‚îÇ
‚îÇ     ‚Üí Appelle model.forward(tensor, hour)                   ‚îÇ
‚îÇ     ‚Üí Applique variations horaires r√©alistes                ‚îÇ
‚îÇ     ‚Üí D√©normalise les valeurs                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. CALCUL DES SCORES                                       ‚îÇ
‚îÇ     ‚Üí Score qualit√© (0-100)                                 ‚îÇ
‚îÇ     ‚Üí Score risque (0-100)                                  ‚îÇ
‚îÇ     ‚Üí Score confiance (bas√© sur fra√Æcheur donn√©es)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. INSERTION EN BASE (predictions_qualite)                 ‚îÇ
‚îÇ     ‚Üí 10 zones √ó 24 heures = 240 pr√©dictions               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 Variations Horaires R√©alistes

```python
def apply_hourly_variations(base_values, hour):
    """
    Applique des variations physiques r√©alistes bas√©es sur l'heure.
    Simule le cycle jour/nuit.
    """
    # Facteur sinuso√Ødal : -1 (6h) ‚Üí +1 (12h) ‚Üí -1 (18h)
    hour_factor = sin((hour - 6) √ó œÄ / 12)
    
    # pH : tr√®s stable, l√©g√®re variation
    ph = base_ph + 0.1 √ó hour_factor + random.normal(0, 0.05)
    
    # Turbidit√© : varie avec activit√© humaine (pic le jour)
    turb = base_turb + 0.8 √ó |hour_factor| + random.normal(0, 0.2)
    
    # Temp√©rature : suit cycle solaire (¬±4¬∞C)
    temp = base_temp + 3.0 √ó hour_factor + random.normal(0, 0.5)
    
    return ph, turb, temp
```

### 5.3 Calcul du Score de Qualit√©

```python
def compute_quality_score(ph, turb, temp):
    """
    Score de qualit√© globale [0-100] bas√© sur les normes OMS.
    """
    # Score pH (40% du total)
    # Optimal: 7.0, acceptable: 6.5-8.5
    ph_score = max(0, 100 - abs(ph - 7.0) √ó 30)
    
    # Score turbidit√© (35% du total)
    # Optimal: < 1 NTU, limite: 5 NTU
    if turb <= 1.0:
        turb_score = 100
    elif turb <= 5.0:
        turb_score = max(0, 80 - (turb - 1) √ó 15)
    else:
        turb_score = max(0, 20 - (turb - 5) √ó 5)
    
    # Score temp√©rature (25% du total)
    # Optimal: < 25¬∞C, limite: 30¬∞C
    if temp <= 25:
        temp_score = 100
    elif temp <= 30:
        temp_score = max(0, 80 - (temp - 25) √ó 10)
    else:
        temp_score = max(0, 30 - (temp - 30) √ó 5)
    
    # Score pond√©r√©
    total = ph_score √ó 0.40 + turb_score √ó 0.35 + temp_score √ó 0.25
    
    # Classification
    if total >= 80: niveau = "Excellente"
    elif total >= 60: niveau = "Bonne"
    elif total >= 40: niveau = "Moyenne"
    else: niveau = "Faible"
    
    return total, niveau
```

### 5.4 Calcul du Score de Confiance

```python
def compute_confidence(zone_data, data_quality):
    """
    Estime la fiabilit√© de la pr√©diction bas√©e sur la qualit√© des donn√©es.
    """
    base = 50.0  # Base de 50%
    
    # Bonus selon la fra√Æcheur des donn√©es
    if zone_data['window'] == '6 hours':
        base += 40.0   # Donn√©es tr√®s r√©centes
    elif zone_data['window'] == '24 hours':
        base += 25.0   # Donn√©es r√©centes
    elif zone_data['window'] == '7 days':
        base += 10.0   # Donn√©es anciennes
    # Sinon donn√©es imput√©es: pas de bonus
    
    # Bonus pour quantit√© de donn√©es
    count_bonus = min(10.0, zone_data['count'] √ó 0.1)
    
    confidence = min(95.0, base + count_bonus)
    return confidence
```

---

## 6Ô∏è‚É£ Technologies Utilis√©es

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Python** | 3.11+ | Langage principal |
| **PyTorch** | 2.x | Framework deep learning |
| **NumPy** | 1.24+ | Calcul num√©rique |
| **psycopg2** | 2.9+ | Connexion PostgreSQL |
| **TimescaleDB** | 2.x | Base de donn√©es time-series |
| **Docker** | 24+ | Conteneurisation |

---

## 7Ô∏è‚É£ Commandes Utiles

```bash
# G√©n√©rer donn√©es historiques (15 jours)
docker exec stmodel python generate_historical_data.py

# Lancer l'entra√Ænement
docker exec stmodel python stmodel.py --train

# Voir les logs du mod√®le
docker logs -f stmodel

# V√©rifier les pr√©dictions en base
docker exec -it timescaledb psql -U postgres -d aquawatch -c \
  "SELECT * FROM predictions_qualite ORDER BY timestamp DESC LIMIT 10;"
```

---

## üë• √âquipe

- **Ghayt El Idrissi Dafali**
- **Reda Bouimakliouine**
- **Souhail Azzimani**
- **Amine Ibnou Chiekh**

**EMSI Marrakech - Ann√©e Universitaire 2025-2026**
